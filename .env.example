# Coding AI Agent - Environment Configuration
# Copy this file to .env and fill in your actual values

# Application Settings
ENVIRONMENT=development
LOG_LEVEL=INFO
API_HOST=0.0.0.0
API_PORT=8002
DEBUG_MODE=true

# LLM Configuration (Required)
# Get your OpenAI API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here
# Optional: Anthropic as backup LLM provider
ANTHROPIC_API_KEY=your-anthropic-api-key-here
LLM_PROVIDER=openai
LLM_MODEL=gpt-4
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=4000

# GitHub Integration (Required)
# Create a personal access token: https://github.com/settings/personal-access-tokens
GITHUB_TOKEN=ghp_your-github-token-here
GITHUB_REPOSITORY=your-username/market-predictor
GITHUB_BASE_URL=https://api.github.com
ALLOWED_REPOSITORIES=your-username/market-predictor,your-username/other-repo

# Git Configuration
WORKSPACE_BASE_PATH=/tmp/coding-agent-workspaces
MARKET_PREDICTOR_REPO_URL=https://github.com/your-username/market-predictor.git
GIT_USER_NAME=Coding AI Agent
GIT_USER_EMAIL=coding-agent@your-domain.com

# Workflow Settings
WORKFLOW_TIMEOUT=1800
TESTING_TIMEOUT=600
MAX_CONCURRENT_TASKS=3
CLEANUP_WORKSPACES=true

# Security Settings
ENABLE_SANDBOXING=true
MAX_WORKSPACE_SIZE=1GB
ALLOWED_FILE_TYPES=.py,.md,.txt,.json,.yml,.yaml,.toml

# Docker Settings
DOCKER_SOCKET_PATH=/var/run/docker.sock
DOCKER_IMAGE_BASE=python:3.9-slim
DOCKER_NETWORK_MODE=bridge

# API Settings
API_KEY=your-optional-api-key-for-authentication
CORS_ORIGINS=*
REQUEST_TIMEOUT=300

# Development Settings (for development environment only)
RELOAD_ON_CHANGE=true
ENABLE_DEBUG_LOGGING=true